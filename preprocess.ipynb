{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 18:11:50,814 - INFO - \n",
      "======= FOLD 1/5 =======\n",
      "2025-03-27 18:11:52,278 - INFO - Fold 1 guardado en /home/diego/Escritorio/santiago/1st_paper/116ROIs/fold_1\n",
      "2025-03-27 18:11:52,278 - INFO - \n",
      "======= FOLD 2/5 =======\n",
      "2025-03-27 18:11:53,406 - INFO - Fold 2 guardado en /home/diego/Escritorio/santiago/1st_paper/116ROIs/fold_2\n",
      "2025-03-27 18:11:53,406 - INFO - \n",
      "======= FOLD 3/5 =======\n",
      "2025-03-27 18:11:54,340 - INFO - Fold 3 guardado en /home/diego/Escritorio/santiago/1st_paper/116ROIs/fold_3\n",
      "2025-03-27 18:11:54,341 - INFO - \n",
      "======= FOLD 4/5 =======\n",
      "2025-03-27 18:11:55,264 - INFO - Fold 4 guardado en /home/diego/Escritorio/santiago/1st_paper/116ROIs/fold_4\n",
      "2025-03-27 18:11:55,265 - INFO - \n",
      "======= FOLD 5/5 =======\n",
      "2025-03-27 18:11:56,212 - INFO - Fold 5 guardado en /home/diego/Escritorio/santiago/1st_paper/116ROIs/fold_5\n",
      "2025-03-27 18:11:56,213 - INFO - Cross-Validation finalizado.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# Montar o configurar Google Drive sólo si corresponde\n",
    "# ...\n",
    "\n",
    "# Paths del proyecto\n",
    "project_dir = '/home/diego/Escritorio/santiago/1st_paper/116ROIs'  # o tu path local\n",
    "csv_path = os.path.join(project_dir, 'DataBaseSubjects.csv')\n",
    "tensor_data_dir = os.path.join(project_dir, 'TensorData')\n",
    "\n",
    "# Cargar config\n",
    "config_path = os.path.join(project_dir, 'config.yaml')\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "seed = config.get('seed', 42)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Leer CSV\n",
    "subjects_df = pd.read_csv(csv_path)\n",
    "\n",
    "# ▶ (Opcional) unificar MCI, EMCI, LMCI en MCI, si lo requieres:\n",
    "def map_3class_group(x):\n",
    "    if x == 'AD': return 'AD'\n",
    "    elif x == 'CN': return 'CN'\n",
    "    else: return 'Others'\n",
    "#subjects_df['ResearchGroup'] = subjects_df['ResearchGroup'].apply(map_3class_group)\n",
    "\n",
    "# Crear etiqueta combinada (ResearchGroup, Sex) para estratificar\n",
    "subjects_df['Group_Sex'] = subjects_df['ResearchGroup'].astype(str) + '_' + subjects_df['Sex'].astype(str)\n",
    "\n",
    "# Construir diccionario con rutas .pt\n",
    "# Ejemplo de cómo se construyen las rutas:\n",
    "\n",
    "grouped_data = subjects_df.groupby(['ResearchGroup','Sex'])['SubjectID'].apply(list).to_dict()\n",
    "\n",
    "tensor_groups = {}\n",
    "for (group, sex), subject_ids in grouped_data.items():\n",
    "    file_paths = []\n",
    "    for sid in subject_ids:\n",
    "        # Usar la convención: {ResearchGroup}_tensor_{SubjectID}.pt\n",
    "        if not os.path.exists(tensor_data_dir):\n",
    "            logging.warning(f\"Missing tensor data dir: {tensor_data_dir}\")\n",
    "            continue\n",
    "\n",
    "        if group not in ['AD', 'CN']:\n",
    "            group = 'Others'\n",
    "        fp = os.path.join(tensor_data_dir, f\"{group}_tensor_{sid}.pt\")\n",
    "        file_paths.append(fp)\n",
    "    tensor_groups[f\"{group}_{sex}\"] = file_paths\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# Funciones para cargar/preprocesar (tomadas de tu script actual):\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "def zero_diagonals(tensor):\n",
    "    idx = torch.arange(tensor.size(1))\n",
    "    tensor[:, idx, idx] = 0\n",
    "    return tensor\n",
    "\n",
    "def load_tensor(fp):\n",
    "    if not os.path.exists(fp):\n",
    "        logging.warning(f\"Missing tensor file: {fp}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        data = torch.load(fp, weights_only=False)\n",
    "        if isinstance(data, np.ndarray):\n",
    "            data = torch.tensor(data)\n",
    "        if not isinstance(data, torch.Tensor):\n",
    "            logging.warning(f\"Unexpected data format: {type(data)} in {fp}\")\n",
    "            return None\n",
    "\n",
    "        # Aquí ejemplo: zero diagonals\n",
    "        data = zero_diagonals(data)\n",
    "\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading {fp}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_tensors(file_paths, batch_size=16):\n",
    "    \"\"\"\n",
    "    Carga tensores de una lista de rutas en batches.\n",
    "    Devuelve un único tensor concatenado, shape: (N, C, H, W)\n",
    "    \"\"\"\n",
    "    all_tensors = []\n",
    "    for i in range(0, len(file_paths), batch_size):\n",
    "        batch_paths = file_paths[i:i+batch_size]\n",
    "        batch = [load_tensor(p) for p in batch_paths]\n",
    "        batch = [t for t in batch if t is not None]\n",
    "        if batch:\n",
    "            all_tensors.extend(batch)\n",
    "\n",
    "    if len(all_tensors) == 0:\n",
    "        return None\n",
    "    return torch.stack(all_tensors)\n",
    "\n",
    "def compute_mean_std_per_channel(dataset):\n",
    "    mean = dataset.mean(dim=(0,2,3))\n",
    "    std = dataset.std(dim=(0,2,3))\n",
    "    std[std==0] = 1e-9\n",
    "    return mean, std\n",
    "\n",
    "def normalize_dataset(dataset, mean, std):\n",
    "    epsilon = 1e-9\n",
    "    return (dataset - mean[None,:,None,None]) / (std[None,:,None,None] + epsilon)\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# Enfoque Cross-Validation:\n",
    "# - Outer folds (p. ej., 5) para dividir en train+val vs. test\n",
    "# - Dentro de cada train+val, hacemos un 80/20 para train vs. val\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "# 1) Construir una lista total de (filepath, label) para luego estratificar\n",
    "X = []\n",
    "y = []\n",
    "for gsex, paths in tensor_groups.items():\n",
    "    # gsex = \"MCI_F\", \"AD_M\", etc.\n",
    "    # O bien, podemos separar con un split real si lo deseas\n",
    "    for fp in paths:\n",
    "        X.append(fp)\n",
    "        # la \"etiqueta\" para estratificar puede ser gsex (o sólo la parte de 'ResearchGroup')\n",
    "        y.append(gsex)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 2) StratifiedKFold\n",
    "outer_folds = 5\n",
    "outer_cv = StratifiedKFold(n_splits=outer_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "fold_idx = 1\n",
    "for train_val_idx, test_idx in outer_cv.split(X, y):\n",
    "    logging.info(f\"\\n======= FOLD {fold_idx}/{outer_folds} =======\")\n",
    "    fold_idx += 1\n",
    "\n",
    "    # Rutas para train+val, test\n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "\n",
    "    # 3) Sep. interna train/val (80/20)\n",
    "    # Notar que aquí NO estamos estratificando por group_sex otra vez; si quieres, puedes hacerlo igual\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        np.arange(len(X_train_val)),\n",
    "        test_size=0.2,\n",
    "        random_state=seed,\n",
    "        stratify=y_train_val  # si deseas estratificar\n",
    "    )\n",
    "    X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "    y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "    # 4) Cargar tensores\n",
    "    train_data = load_tensors(list(X_train))\n",
    "    val_data = load_tensors(list(X_val))\n",
    "    test_data = load_tensors(list(X_test))\n",
    "\n",
    "    if train_data is None or val_data is None or test_data is None:\n",
    "        logging.warning(\"Algún split no pudo cargar tensores. Se omite este fold.\")\n",
    "        continue\n",
    "\n",
    "    # 5) Calcular stats en train\n",
    "    train_mean, train_std = compute_mean_std_per_channel(train_data)\n",
    "    # Normalizar\n",
    "    train_data = normalize_dataset(train_data, train_mean, train_std)\n",
    "    val_data = normalize_dataset(val_data, train_mean, train_std)\n",
    "    test_data = normalize_dataset(test_data, train_mean, train_std)\n",
    "\n",
    "    # 6) Guardar o procesar, según necesites\n",
    "    # Por ejemplo, guardamos en una carpeta fold_k\n",
    "    fold_dir = os.path.join(project_dir, f'fold_{fold_idx-1}')\n",
    "    os.makedirs(fold_dir, exist_ok=True)\n",
    "\n",
    "    torch.save(train_data, os.path.join(fold_dir, 'train_data.pt'))\n",
    "    torch.save(val_data,   os.path.join(fold_dir, 'val_data.pt'))\n",
    "    torch.save(test_data,  os.path.join(fold_dir, 'test_data.pt'))\n",
    "\n",
    "    logging.info(f\"Fold {fold_idx-1} guardado en {fold_dir}\")\n",
    "\n",
    "logging.info(\"Cross-Validation finalizado.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
